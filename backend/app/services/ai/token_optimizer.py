"""
TokenèŠ‚çœä¼˜åŒ–æœåŠ¡ - é«˜æ æ†ç­–ç•¥å®ç°

åŠŸèƒ½ï¼š
1. å†…å®¹é¢„å¤„ç†å’Œæˆªæ–­
2. æ‰¹é‡å¤„ç†å‡å°‘APIè°ƒç”¨
3. æ™ºèƒ½é‡‡æ ·ç­–ç•¥
4. è¾“å‡ºæ ¼å¼ä¼˜åŒ–
5. é¢„ç®—æ§åˆ¶å’Œç†”æ–­

é’ˆå¯¹ç¡¬ä»¶é…ç½®ï¼ši5-11260H/16GB/RTX 3050 4GB
"""

import asyncio
import logging
import hashlib
import json
from typing import List, Dict, Any, Optional, Tuple
from datetime import datetime, timedelta
from dataclasses import dataclass

from app.core.config import settings
from app.services.cache.redis_service import redis_service

logger = logging.getLogger(__name__)


@dataclass
class TokenBudget:
    """Tokené¢„ç®—ç®¡ç†"""
    daily_limit: int
    hourly_limit: int
    current_daily: int = 0
    current_hourly: int = 0
    last_reset_hour: int = 0
    last_reset_day: int = 0


class TokenOptimizer:
    """TokenèŠ‚çœä¼˜åŒ–å™¨"""
    
    def __init__(self):
        self.enabled = getattr(settings, 'TOKEN_SAVE_ENABLED', True)
        self.content_max_length = getattr(settings, 'TOKEN_SAVE_CONTENT_MAX_LENGTH', 500)
        self.reason_max_length = getattr(settings, 'TOKEN_SAVE_REASON_MAX_LENGTH', 50)
        self.batch_size = getattr(settings, 'TOKEN_SAVE_BATCH_SIZE', 10)
        self.sampling_rate = getattr(settings, 'TOKEN_SAVE_SAMPLING_RATE', 0.3)
        
        # é¢„ç®—æ§åˆ¶
        self.budget = TokenBudget(
            daily_limit=getattr(settings, 'CLOUD_DAILY_BUDGET_CALLS', 1000),
            hourly_limit=getattr(settings, 'CLOUD_HOURLY_BUDGET_CALLS', 100)
        )
        
        # æ‰¹å¤„ç†é˜Ÿåˆ—
        self._batch_queue: List[Dict[str, Any]] = []
        self._batch_lock = asyncio.Lock()
        
        logger.info(f"Tokenä¼˜åŒ–å™¨åˆå§‹åŒ–: enabled={self.enabled}, sampling_rate={self.sampling_rate}")
    
    async def should_process_content(self, content: str, content_type: str, priority: str = "normal") -> bool:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥å¤„ç†å†…å®¹ï¼ˆæ™ºèƒ½é‡‡æ ·ç­–ç•¥ï¼‰
        
        Args:
            content: å†…å®¹æ–‡æœ¬
            content_type: å†…å®¹ç±»å‹
            priority: ä¼˜å…ˆçº§ (high/normal/low)
        
        Returns:
            bool: æ˜¯å¦åº”è¯¥å¤„ç†
        """
        if not self.enabled:
            return True
        
        # é«˜ä¼˜å…ˆçº§å†…å®¹æ€»æ˜¯å¤„ç†
        if priority == "high":
            return True
        
        # æ£€æŸ¥é¢„ç®—é™åˆ¶
        if not await self._check_budget():
            logger.warning("Tokené¢„ç®—å·²è€—å°½ï¼Œè·³è¿‡å¤„ç†")
            return False
        
        # å†…å®¹é•¿åº¦è¿‡çŸ­ï¼Œè·³è¿‡ï¼ˆå¯èƒ½æ˜¯æ— æ„ä¹‰å†…å®¹ï¼‰
        if len(content.strip()) < 5:
            return False
        
        # é‡‡æ ·ç­–ç•¥ï¼šæ ¹æ®å†…å®¹å“ˆå¸Œå†³å®šæ˜¯å¦å¤„ç†
        content_hash = hashlib.md5(content.encode()).hexdigest()
        hash_int = int(content_hash[:8], 16)
        
        # ä½ä¼˜å…ˆçº§å†…å®¹æŒ‰é‡‡æ ·ç‡å¤„ç†
        if priority == "low":
            return (hash_int % 100) < (self.sampling_rate * 50)  # é™ä½é‡‡æ ·ç‡
        
        # æ™®é€šä¼˜å…ˆçº§å†…å®¹æŒ‰æ­£å¸¸é‡‡æ ·ç‡å¤„ç†
        return (hash_int % 100) < (self.sampling_rate * 100)
    
    def optimize_content_for_llm(self, content: str, content_type: str) -> str:
        """
        ä¼˜åŒ–å†…å®¹ä»¥å‡å°‘Tokenæ¶ˆè€—
        
        Args:
            content: åŸå§‹å†…å®¹
            content_type: å†…å®¹ç±»å‹
        
        Returns:
            str: ä¼˜åŒ–åçš„å†…å®¹
        """
        if not self.enabled:
            return content
        
        # 1. å»é™¤å¤šä½™ç©ºç™½å­—ç¬¦
        optimized = ' '.join(content.split())
        
        # 2. é•¿åº¦æˆªæ–­ï¼ˆä¿ç•™é‡è¦ä¿¡æ¯ï¼‰
        if len(optimized) > self.content_max_length:
            # æ™ºèƒ½æˆªæ–­ï¼šä¿ç•™å¼€å¤´å’Œç»“å°¾
            half_length = self.content_max_length // 2 - 10
            optimized = optimized[:half_length] + "..." + optimized[-half_length:]
        
        # 3. ç§»é™¤é‡å¤å­—ç¬¦ï¼ˆå¦‚å¤šä¸ªæ„Ÿå¹å·ï¼‰
        import re
        optimized = re.sub(r'([!?ã€‚ï¼Œ])\1{2,}', r'\1\1', optimized)
        
        # 4. è¡¨æƒ…ç¬¦å·å‹ç¼©
        optimized = re.sub(r'[ğŸ˜€-ğŸ™]{3,}', 'ğŸ˜Š', optimized)
        
        return optimized
    
    def optimize_prompt_for_llm(self, system_prompt: str) -> str:
        """
        ä¼˜åŒ–ç³»ç»ŸPromptä»¥å‡å°‘Tokenæ¶ˆè€—
        
        Args:
            system_prompt: åŸå§‹ç³»ç»ŸPrompt
        
        Returns:
            str: ä¼˜åŒ–åçš„Prompt
        """
        if not self.enabled:
            return system_prompt
        
        # ç§»é™¤å¤šä½™çš„ç¤ºä¾‹å’Œè§£é‡Š
        optimized = system_prompt
        
        # å‹ç¼©JSONæ ¼å¼è¦æ±‚
        json_format = '{"score":0-100,"category":"ç±»åˆ«","label":"æ ‡ç­¾","reason":"ç®€çŸ­åŸå› ","confidence":0.0-1.0}'
        
        # æ›¿æ¢å†—é•¿çš„JSONæ ¼å¼è¯´æ˜
        import re
        optimized = re.sub(
            r'è¿”å›æ ¼å¼.*?```json.*?```',
            f'è¿”å›JSONæ ¼å¼: {json_format}',
            optimized,
            flags=re.DOTALL
        )
        
        return optimized
    
    def optimize_llm_response(self, response: Dict[str, Any]) -> Dict[str, Any]:
        """
        ä¼˜åŒ–LLMå“åº”ä»¥å‡å°‘å­˜å‚¨å’Œä¼ è¾“æˆæœ¬
        
        Args:
            response: åŸå§‹å“åº”
        
        Returns:
            Dict: ä¼˜åŒ–åçš„å“åº”
        """
        if not self.enabled:
            return response
        
        optimized = response.copy()
        
        # æˆªæ–­reasonå­—æ®µ
        if 'reason' in optimized and len(optimized['reason']) > self.reason_max_length:
            optimized['reason'] = optimized['reason'][:self.reason_max_length] + "..."
        
        # ç§»é™¤ä¸å¿…è¦çš„å­—æ®µ
        unnecessary_fields = ['raw_response', 'debug_info', 'model_version']
        for field in unnecessary_fields:
            optimized.pop(field, None)
        
        return optimized
    
    async def add_to_batch(self, content: str, content_type: str, callback_id: str) -> bool:
        """
        æ·»åŠ åˆ°æ‰¹å¤„ç†é˜Ÿåˆ—
        
        Args:
            content: å†…å®¹
            content_type: ç±»å‹
            callback_id: å›è°ƒID
        
        Returns:
            bool: æ˜¯å¦æˆåŠŸæ·»åŠ 
        """
        if not self.enabled:
            return False
        
        async with self._batch_lock:
            self._batch_queue.append({
                'content': content,
                'content_type': content_type,
                'callback_id': callback_id,
                'timestamp': datetime.utcnow()
            })
            
            # é˜Ÿåˆ—æ»¡äº†æˆ–è¶…æ—¶ï¼Œè§¦å‘æ‰¹å¤„ç†
            if len(self._batch_queue) >= self.batch_size:
                await self._process_batch()
                return True
        
        return False
    
    async def _process_batch(self):
        """å¤„ç†æ‰¹é‡é˜Ÿåˆ—"""
        if not self._batch_queue:
            return
        
        batch = self._batch_queue.copy()
        self._batch_queue.clear()
        
        logger.info(f"å¼€å§‹æ‰¹å¤„ç† {len(batch)} ä¸ªå†…å®¹")
        
        # è¿™é‡Œå¯ä»¥å®ç°æ‰¹é‡è°ƒç”¨LLMçš„é€»è¾‘
        # æš‚æ—¶è®°å½•æ—¥å¿—
        for item in batch:
            logger.debug(f"æ‰¹å¤„ç†é¡¹ç›®: {item['callback_id']}")
    
    async def _check_budget(self) -> bool:
        """æ£€æŸ¥Tokené¢„ç®—æ˜¯å¦å……è¶³"""
        try:
            now = datetime.utcnow()
            current_hour = now.hour
            current_day = now.day
            
            # é‡ç½®å°æ—¶è®¡æ•°
            if current_hour != self.budget.last_reset_hour:
                self.budget.current_hourly = 0
                self.budget.last_reset_hour = current_hour
            
            # é‡ç½®æ—¥è®¡æ•°
            if current_day != self.budget.last_reset_day:
                self.budget.current_daily = 0
                self.budget.last_reset_day = current_day
            
            # ä»Redisè·å–å®é™…ä½¿ç”¨é‡
            daily_key = f"token_budget:daily:{now.strftime('%Y%m%d')}"
            hourly_key = f"token_budget:hourly:{now.strftime('%Y%m%d%H')}"
            
            daily_used = await redis_service.async_redis.get(daily_key) or 0
            hourly_used = await redis_service.async_redis.get(hourly_key) or 0
            
            self.budget.current_daily = int(daily_used)
            self.budget.current_hourly = int(hourly_used)
            
            # æ£€æŸ¥æ˜¯å¦è¶…å‡ºé™åˆ¶
            if self.budget.current_daily >= self.budget.daily_limit:
                return False
            
            if self.budget.current_hourly >= self.budget.hourly_limit:
                return False
            
            return True
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥Tokené¢„ç®—å¤±è´¥: {e}")
            return True  # å‡ºé”™æ—¶å…è®¸å¤„ç†ï¼Œé¿å…é˜»å¡
    
    async def record_token_usage(self, tokens_used: int):
        """è®°å½•Tokenä½¿ç”¨é‡"""
        try:
            now = datetime.utcnow()
            daily_key = f"token_budget:daily:{now.strftime('%Y%m%d')}"
            hourly_key = f"token_budget:hourly:{now.strftime('%Y%m%d%H')}"
            
            # å¢åŠ ä½¿ç”¨é‡
            await redis_service.async_redis.incr(daily_key)
            await redis_service.async_redis.incr(hourly_key)
            
            # è®¾ç½®è¿‡æœŸæ—¶é—´
            await redis_service.async_redis.expire(daily_key, 86400)  # 24å°æ—¶
            await redis_service.async_redis.expire(hourly_key, 3600)   # 1å°æ—¶
            
            # æ›´æ–°å†…å­˜è®¡æ•°
            self.budget.current_daily += tokens_used
            self.budget.current_hourly += tokens_used
            
        except Exception as e:
            logger.error(f"è®°å½•Tokenä½¿ç”¨é‡å¤±è´¥: {e}")
    
    def get_budget_status(self) -> Dict[str, Any]:
        """è·å–é¢„ç®—çŠ¶æ€"""
        return {
            "daily": {
                "used": self.budget.current_daily,
                "limit": self.budget.daily_limit,
                "remaining": max(0, self.budget.daily_limit - self.budget.current_daily),
                "usage_rate": self.budget.current_daily / self.budget.daily_limit if self.budget.daily_limit > 0 else 0
            },
            "hourly": {
                "used": self.budget.current_hourly,
                "limit": self.budget.hourly_limit,
                "remaining": max(0, self.budget.hourly_limit - self.budget.current_hourly),
                "usage_rate": self.budget.current_hourly / self.budget.hourly_limit if self.budget.hourly_limit > 0 else 0
            },
            "enabled": self.enabled,
            "sampling_rate": self.sampling_rate
        }
    
    async def get_optimization_stats(self) -> Dict[str, Any]:
        """è·å–ä¼˜åŒ–ç»Ÿè®¡ä¿¡æ¯"""
        try:
            # ä»Redisè·å–ç»Ÿè®¡æ•°æ®
            stats_key = "token_optimizer:stats"
            stats_data = await redis_service.async_redis.hgetall(stats_key)
            
            return {
                "total_processed": int(stats_data.get("total_processed", 0)),
                "total_skipped": int(stats_data.get("total_skipped", 0)),
                "total_tokens_saved": int(stats_data.get("total_tokens_saved", 0)),
                "batch_processed": int(stats_data.get("batch_processed", 0)),
                "average_content_reduction": float(stats_data.get("avg_reduction", 0.0)),
                "last_updated": stats_data.get("last_updated", "æœªçŸ¥")
            }
        except Exception as e:
            logger.error(f"è·å–ä¼˜åŒ–ç»Ÿè®¡å¤±è´¥: {e}")
            return {}


# å…¨å±€å®ä¾‹
token_optimizer = TokenOptimizer()