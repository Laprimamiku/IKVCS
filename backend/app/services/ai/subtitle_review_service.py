"""
å­—å¹•å®¡æ ¸æœåŠ¡ï¼ˆæ”¯æŒäº‘ç«¯å’Œæœ¬åœ°æ¨¡å‹ï¼‰

èŒè´£ï¼š
1. è°ƒç”¨äº‘ç«¯æˆ–æœ¬åœ°æ¨¡å‹åˆ†æå­—å¹•å†…å®¹
2. æ£€æµ‹è¿è§„å†…å®¹ï¼ˆæš´åŠ›ã€è¡€è…¥ã€è‰²æƒ…ã€æ”¿æ²»æ•æ„Ÿç­‰ï¼‰
3. è¿”å›å®¡æ ¸ç»“æœå’Œè¯„åˆ†
"""

import httpx
import json
import logging
import re
from typing import Optional, Dict, Any

from app.core.config import settings

logger = logging.getLogger(__name__)

# å­—å¹•å®¡æ ¸ä¸“ç”¨ Prompt
SUBTITLE_REVIEW_PROMPT = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹å®¡æ ¸å‘˜ã€‚è¯·åˆ†æä»¥ä¸‹è§†é¢‘å­—å¹•å†…å®¹ï¼Œåˆ¤æ–­æ˜¯å¦åŒ…å«è¿è§„å†…å®¹ã€‚

è¿è§„å†…å®¹ç±»å‹ï¼š
1. æš´åŠ›å†…å®¹ï¼šæè¿°æš´åŠ›è¡Œä¸ºã€ä¼¤å®³ã€æ­¦å™¨ç­‰
2. è¡€è…¥å†…å®¹ï¼šæè¿°è¡€è…¥åœºæ™¯ã€ææ€–å†…å®¹ç­‰
3. è‰²æƒ…å†…å®¹ï¼šæ€§æš—ç¤ºã€è£¸éœ²æè¿°ç­‰
4. æ”¿æ²»æ•æ„Ÿï¼šæ¶‰åŠæ•æ„Ÿæ”¿æ²»è¯é¢˜
5. å…¶ä»–ä¸å½“å†…å®¹ï¼šè¿æ³•ã€ä½ä¿—ç­‰

è¯·ä»¥JSONæ ¼å¼è¿”å›åˆ†æç»“æœï¼š
{
    "is_violation": true/false,
    "is_suspicious": true/false,
    "violation_type": "violence/blood/porn/political/other/none",
    "score": 0-100,
    "description": "è¯¦ç»†æè¿°"
}

è¯„åˆ†æ ‡å‡†ï¼š
- 0-30: æ˜æ˜¾è¿è§„ï¼Œå¿…é¡»æ‹’ç»
- 31-60: ç–‘ä¼¼è¿è§„ï¼Œéœ€è¦äººå·¥å®¡æ ¸
- 61-100: æ­£å¸¸å†…å®¹ï¼Œå¯ä»¥å‘å¸ƒ

è¯·åŠ¡å¿…åªè¿”å› JSON æ ¼å¼ç»“æœï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°æˆ–å…¶ä»–è§£é‡Šæ–‡æœ¬ã€‚"""


class SubtitleReviewService:
    """å­—å¹•å®¡æ ¸æœåŠ¡ï¼ˆæ”¯æŒäº‘ç«¯å’Œæœ¬åœ°æ¨¡å‹ï¼‰"""
    
    def __init__(self):
        self.local_base_url = settings.LOCAL_LLM_BASE_URL.rstrip("/")
        self.local_model = settings.LOCAL_LLM_MODEL
        self.local_timeout = settings.LOCAL_LLM_TIMEOUT
        self.mode = getattr(settings, "LLM_MODE", "hybrid").lower()
        self.use_cloud = self.mode in ("cloud_only", "hybrid") and bool(settings.LLM_API_KEY)
        # å­—å¹•å®¡æ ¸ç”±äº‘ç«¯æ¨¡å‹è´Ÿè´£ï¼›æœ¬åœ°æ¨¡å‹ä¸ç”¨äºå­—å¹•å®¡æ ¸ï¼ˆå¯åç»­æ‰©å±•ï¼‰
        self.use_local = False
    
    async def review_subtitle(
        self,
        subtitle_text: str
    ) -> Optional[Dict[str, Any]]:
        """
        å®¡æ ¸å­—å¹•å†…å®¹
        
        å‚æ•°:
            subtitle_text: å­—å¹•æ–‡æœ¬å†…å®¹
        
        è¿”å›:
            Dict: å®¡æ ¸ç»“æœ
                - is_violation: bool - æ˜¯å¦è¿è§„
                - is_suspicious: bool - æ˜¯å¦ç–‘ä¼¼è¿è§„
                - violation_type: str - è¿è§„ç±»å‹
                - score: int - å®¡æ ¸è¯„åˆ†ï¼ˆ0-100ï¼‰
                - description: str - å®¡æ ¸æè¿°
        """
        if not subtitle_text or len(subtitle_text.strip()) == 0:
            return {
                "is_violation": False,
                "is_suspicious": False,
                "violation_type": "none",
                "score": 100,
                "description": "å­—å¹•ä¸ºç©ºï¼Œæ— éœ€å®¡æ ¸"
            }

        if self.mode == "off":
            return {
                "is_violation": False,
                "is_suspicious": False,
                "violation_type": "none",
                "score": 100,
                "description": "LLM_MODE=offï¼Œè·³è¿‡å­—å¹•å®¡æ ¸"
            }
        
        # å­—å¹•å®¡æ ¸ï¼šç»Ÿä¸€èµ°äº‘ç«¯ï¼ˆå½“å‰ä¸ä½¿ç”¨æœ¬åœ°æ¨¡å‹è¿›è¡Œå­—å¹•å®¡æ ¸ï¼‰
        if self.use_cloud:
            logger.info(f"[SubtitleReview] è°ƒç”¨äº‘ç«¯æ¨¡å‹: {settings.LLM_MODEL} @ {settings.LLM_BASE_URL}")
            cloud = await self._review_with_cloud_model(subtitle_text)
            if cloud is not None:
                return cloud
            logger.warning("[SubtitleReview] äº‘ç«¯æ¨¡å‹å®¡æ ¸å¤±è´¥")

        logger.warning("[SubtitleReview] äº‘ç«¯æ¨¡å‹ä¸å¯ç”¨ï¼Œè¿”å›é»˜è®¤é€šè¿‡ï¼ˆå¯æ”¹ä¸ºç–‘ä¼¼ä»¥è§¦å‘äººå·¥å¤æ ¸ï¼‰")
        return {
            "is_violation": False,
            "is_suspicious": False,
            "violation_type": "none",
            "score": 100,
            "description": "äº‘ç«¯æ¨¡å‹ä¸å¯ç”¨ï¼Œè·³è¿‡å®¡æ ¸"
        }
    
    async def _review_with_cloud_model(
        self,
        subtitle_text: str
    ) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨äº‘ç«¯æ¨¡å‹å®¡æ ¸å­—å¹•"""
        try:
            # é™åˆ¶è¾“å…¥æ–‡æœ¬é•¿åº¦ï¼Œé¿å…è¶…è¿‡æ¨¡å‹é™åˆ¶
            max_input_length = getattr(settings, "CLOUD_MAX_INPUT_CHARS_PER_VIDEO", 8000) or 8000
            if len(subtitle_text) > max_input_length:
                logger.warning(f"å­—å¹•æ–‡æœ¬è¿‡é•¿ ({len(subtitle_text)} å­—ç¬¦)ï¼Œæˆªå–å‰ {max_input_length} å­—ç¬¦")
                subtitle_text = subtitle_text[:max_input_length] + "...[æ–‡æœ¬å·²æˆªæ–­]"
            
            # ä»é…ç½®è¯»å–APIä¿¡æ¯ï¼ˆç¡®ä¿å…¨å±€ç»Ÿä¸€é…ç½®ï¼‰
            api_key = settings.LLM_API_KEY
            base_url = settings.LLM_BASE_URL.rstrip("/")
            model = settings.LLM_MODEL
            timeout = 30.0
            
            # è®°å½•å½“å‰ä½¿ç”¨çš„é…ç½®ï¼ˆä¾¿äºè°ƒè¯•å’Œç¡®è®¤æ¨¡å‹åˆ‡æ¢ï¼‰
            logger.info(f"[SubtitleReview] ğŸ“‹ å­—å¹•å®¡æ ¸é…ç½®: API={base_url}, Model={model}")
            
            headers = {
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json",
            }
            
            payload = {
                "model": model,
                "messages": [
                    {"role": "system", "content": SUBTITLE_REVIEW_PROMPT},
                    {"role": "user", "content": f"å­—å¹•å†…å®¹ï¼š\n{subtitle_text}"}
                ],
                "temperature": 0.1,
                "max_tokens": 512,  # å¢åŠ tokené™åˆ¶ï¼Œç¡®ä¿å®Œæ•´çš„JSONå“åº”
            }
            
            async with httpx.AsyncClient(timeout=timeout) as client:
                response = await client.post(
                    f"{base_url}/chat/completions",
                    json=payload,
                    headers=headers,
                )
                
                if response.status_code != 200:
                    logger.error(f"äº‘ç«¯å­—å¹•å®¡æ ¸APIé”™è¯¯: {response.status_code} - {response.text}")
                    return None
                
                response_data = response.json()
                response_text = response_data.get("choices", [{}])[0].get("message", {}).get("content", "")
                
                if not response_text:
                    logger.warning("äº‘ç«¯æ¨¡å‹è¿”å›ç©ºå“åº”")
                    return None
                
                return self._parse_review_response(response_text)
                
        except Exception as e:
            logger.error(f"äº‘ç«¯å­—å¹•å®¡æ ¸å¤±è´¥: {e}")
            return None
    
    async def _review_with_local_model(
        self,
        subtitle_text: str
    ) -> Optional[Dict[str, Any]]:
        """ä½¿ç”¨æœ¬åœ°æ¨¡å‹å®¡æ ¸å­—å¹•"""
        if not self.local_base_url or not self.local_model:
            logger.warning("æœ¬åœ°å­—å¹•å®¡æ ¸é…ç½®ç¼ºå¤±ï¼ˆbase_url/modelï¼‰ï¼Œè·³è¿‡å­—å¹•å®¡æ ¸")
            return None
        
        try:
            # trust_env=False: avoid routing localhost through system proxy
            async with httpx.AsyncClient(timeout=self.local_timeout, trust_env=False) as client:
                response = await client.post(
                    f"{self.local_base_url}/chat/completions",
                    json={
                        "model": self.local_model,
                        "messages": [
                            {"role": "system", "content": SUBTITLE_REVIEW_PROMPT},
                            {"role": "user", "content": f"å­—å¹•å†…å®¹ï¼š\n{subtitle_text}"}
                        ],
                        "temperature": 0.1,
                        "max_tokens": 256,
                        "stream": False
                    }
                )
                
                if response.status_code != 200:
                    logger.error(f"æœ¬åœ°å­—å¹•å®¡æ ¸APIé”™è¯¯: {response.status_code} - {response.text}")
                    return None
                
                response_data = response.json()
                response_text = response_data.get("choices", [{}])[0].get("message", {}).get("content", "")
                
                if not response_text:
                    logger.warning("æœ¬åœ°æ¨¡å‹è¿”å›ç©ºå“åº”")
                    return None
                
                return self._parse_review_response(response_text)
                
        except Exception as e:
            logger.error(f"æœ¬åœ°å­—å¹•å®¡æ ¸å¤±è´¥: {e}")
            return None
    
    def _parse_review_response(self, response_text: str) -> Optional[Dict[str, Any]]:
        """è§£æå®¡æ ¸å“åº”"""
        try:
            # æ¸…ç†å“åº”æ–‡æœ¬ï¼Œç§»é™¤å¯èƒ½çš„ Markdown æ ‡è®°
            clean_text = response_text.strip()
            if clean_text.startswith("```json"):
                clean_text = clean_text[7:]
            if clean_text.endswith("```"):
                clean_text = clean_text[:-3]
            clean_text = clean_text.strip()
            
            # å°è¯•ç›´æ¥è§£æJSON
            try:
                result = json.loads(clean_text)
            except json.JSONDecodeError as e:
                # å¦‚æœJSONè¢«æˆªæ–­ï¼Œå°è¯•ä¿®å¤
                logger.warning(f"JSONè§£æå¤±è´¥ï¼Œå°è¯•ä¿®å¤æˆªæ–­çš„JSON: {e}")
                result = self._try_fix_truncated_json(clean_text)
                if result is None:
                    raise e
            
            # éªŒè¯å¿…éœ€å­—æ®µ
            required_fields = ["is_violation", "is_suspicious", "violation_type", "score", "description"]
            for field in required_fields:
                if field not in result:
                    logger.warning(f"å®¡æ ¸å“åº”ç¼ºå°‘å­—æ®µ: {field}")
                    return self._create_default_response(80, "å†…å®¹æ­£å¸¸", "å­—æ®µä¸å®Œæ•´ï¼Œä½¿ç”¨é»˜è®¤ç»“æœ")
            
            # ç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
            result["is_violation"] = bool(result["is_violation"])
            result["is_suspicious"] = bool(result["is_suspicious"])
            result["score"] = int(result["score"])
            
            return result
            
        except (json.JSONDecodeError, ValueError, KeyError) as e:
            logger.error(f"è§£æå­—å¹•å®¡æ ¸å“åº”å¤±è´¥: {e}, å“åº”å†…å®¹: {response_text[:200]}...")
            # ä½¿ç”¨æ™ºèƒ½å¤‡ç”¨è§£ææ–¹æ³•
            return self._intelligent_fallback_parse(response_text)
    
    def _try_fix_truncated_json(self, text: str) -> Optional[Dict[str, Any]]:
        """å°è¯•ä¿®å¤è¢«æˆªæ–­çš„JSON"""
        try:
            # å¦‚æœJSONè¢«æˆªæ–­ï¼Œå°è¯•æ‰¾åˆ°æœ€åä¸€ä¸ªå®Œæ•´çš„å­—æ®µ
            # æŸ¥æ‰¾æœ€åä¸€ä¸ªé€—å·æˆ–å¼•å·çš„ä½ç½®
            last_comma = text.rfind(',')
            last_quote = text.rfind('"')
            
            if last_comma > 0 and last_quote > last_comma:
                # å°è¯•åœ¨æœ€åä¸€ä¸ªé€—å·å¤„æˆªæ–­å¹¶æ·»åŠ ç»“æŸç¬¦
                truncated = text[:last_comma] + '}'
                return json.loads(truncated)
            elif last_quote > 0:
                # å°è¯•åœ¨æœ€åä¸€ä¸ªå¼•å·åæ·»åŠ ç»“æŸç¬¦
                truncated = text[:last_quote + 1] + '}'
                return json.loads(truncated)
            
            return None
        except:
            return None
    
    def _create_default_response(self, score: int, violation_type: str, description: str) -> Dict[str, Any]:
        """åˆ›å»ºé»˜è®¤å“åº”"""
        return {
            "is_violation": score < 30,
            "is_suspicious": 30 <= score < 60,
            "violation_type": violation_type if score < 60 else "none",
            "score": score,
            "description": description
        }
    
    def _intelligent_fallback_parse(self, text: str) -> Dict[str, Any]:
        """æ™ºèƒ½å¤‡ç”¨è§£ææ–¹æ³•ï¼ˆåŸºäºä¸Šä¸‹æ–‡åˆ†æï¼‰"""
        text_lower = text.lower()
        
        # é¦–å…ˆæ£€æŸ¥æ˜¯å¦æ˜¯å­¦æœ¯/æ•™è‚²å†…å®¹
        educational_indicators = [
            "å­¦æœ¯", "æ•™è‚²", "ç§‘æ™®", "åˆ†æ", "ç ”ç©¶", "ç»Ÿè®¡", "æ•°æ®", "ç†è®º",
            "academic", "educational", "analysis", "research", "study", "statistics"
        ]
        
        is_educational = any(indicator in text_lower for indicator in educational_indicators)
        
        # æ£€æµ‹çœŸæ­£çš„è¿è§„å…³é”®è¯ï¼ˆéœ€è¦ä¸Šä¸‹æ–‡åˆ¤æ–­ï¼‰
        violation_keywords = ["è‰²æƒ…", "è£¸ä½“", "æ€§è¡Œä¸º", "porn", "nude", "sex act"]
        violence_keywords = ["æ€äºº", "ä¼¤å®³ä»–äºº", "æš´åŠ›è¡Œä¸º", "murder", "harm others", "violent act"]
        
        # å¦‚æœæ˜¯æ•™è‚²å†…å®¹ï¼Œå³ä½¿åŒ…å«æ•æ„Ÿè¯æ±‡ä¹Ÿä¸åº”è¯¥è¢«æ ‡è®°ä¸ºè¿è§„
        if is_educational:
            # å¯¹äºæ•™è‚²å†…å®¹ï¼Œç»™äºˆè¾ƒé«˜è¯„åˆ†
            return {
                "is_violation": False,
                "is_suspicious": False,
                "violation_type": "none",
                "score": 85,
                "description": "æ•™è‚²/å­¦æœ¯å†…å®¹ï¼Œè™½ç„¶æ¶‰åŠæ•æ„Ÿè¯é¢˜ä½†å±äºæ­£å¸¸è®¨è®ºèŒƒå›´"
            }
        
        # æ£€æµ‹æ˜æ˜¾è¿è§„å†…å®¹ï¼ˆéæ•™è‚²è¯­å¢ƒä¸‹ï¼‰
        if any(keyword in text_lower for keyword in violation_keywords):
            return {
                "is_violation": True,
                "is_suspicious": False,
                "violation_type": "porn",
                "score": 20,
                "description": "æ£€æµ‹åˆ°è‰²æƒ…ç›¸å…³å†…å®¹"
            }
        
        if any(keyword in text_lower for keyword in violence_keywords):
            return {
                "is_violation": True,
                "is_suspicious": False,
                "violation_type": "violence",
                "score": 25,
                "description": "æ£€æµ‹åˆ°æš´åŠ›ç›¸å…³å†…å®¹"
            }
        
        # æ£€æµ‹ç–‘ä¼¼è¿è§„ï¼ˆéœ€è¦äººå·¥å®¡æ ¸ï¼‰
        suspicious_keywords = ["æ”¿æ²»æ•æ„Ÿ", "äº‰è®®è¯é¢˜", "sensitive political", "controversial"]
        if any(keyword in text_lower for keyword in suspicious_keywords):
            return {
                "is_violation": False,
                "is_suspicious": True,
                "violation_type": "political",
                "score": 50,
                "description": "å†…å®¹æ¶‰åŠæ•æ„Ÿè¯é¢˜ï¼Œå»ºè®®äººå·¥å®¡æ ¸"
            }
        
        # é»˜è®¤ä¸ºæ­£å¸¸å†…å®¹
        return {
            "is_violation": False,
            "is_suspicious": False,
            "violation_type": "none",
            "score": 75,
            "description": "è§£æå¤±è´¥ï¼Œä½†æœªæ£€æµ‹åˆ°æ˜æ˜¾è¿è§„å†…å®¹"
        }


# å…¨å±€å®ä¾‹
subtitle_review_service = SubtitleReviewService()
